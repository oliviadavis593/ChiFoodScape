{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded portal export: 35681 rows\n",
      "üìâ Deduplicated to: 4503 unique locations\n",
      "‚úÖ Cleaned dataset saved to: ../data/cleaned/food_inspections_cleaned.csv\n",
      "üó∫Ô∏è Map saved to: ../maps/grocery_stores_chicago_map.html\n",
      "‚úÖ grocery_stores_cleaned_v1.csv saved!\n"
     ]
    }
   ],
   "source": [
    "# üß† Imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import folium\n",
    "import re\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# üìç File paths\n",
    "RAW_PATH = '../data/raw/food_inspections_filtered.csv'  # ‚Üê filtered export from Chicago Data Portal\n",
    "CLEAN_PATH = '../data/cleaned/food_inspections_cleaned.csv'\n",
    "MAP_PATH = '../maps/grocery_stores_chicago_map.html'\n",
    "\n",
    "# üßæ Load dataset\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "print(f\"‚úÖ Loaded portal export: {df.shape[0]} rows\")\n",
    "\n",
    "# ‚úÇÔ∏è Keep only relevant columns\n",
    "columns_to_keep = [\n",
    "    'DBA Name', 'Address', 'City', 'State', 'Zip',\n",
    "    'Inspection Date', 'Results', 'Violations',\n",
    "    'Latitude', 'Longitude'\n",
    "]\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "# üßπ Drop rows with missing or invalid coordinates\n",
    "df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "df = df[(df['Latitude'] != '') & (df['Longitude'] != '')]\n",
    "\n",
    "# üî† Normalize key fields\n",
    "df['DBA Name'] = df['DBA Name'].str.title().str.strip()\n",
    "df['Address'] = df['Address'].str.title().str.strip()\n",
    "df['Results'] = df['Results'].str.title().str.strip()\n",
    "\n",
    "# Remove any leftover rows missing name/address\n",
    "df = df[df['Address'].notnull() & df['DBA Name'].notnull()]\n",
    "\n",
    "# Normalize for pattern matching\n",
    "df['DBA_NAME_CLEAN'] = (\n",
    "    df['DBA Name']\n",
    "    .str.upper()\n",
    "    .str.replace(r'[^A-Z0-9\\s]', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "df['ADDRESS_CLEAN'] = (\n",
    "    df['Address']\n",
    "    .str.upper()\n",
    "    .str.replace(r'[^A-Z0-9\\s]', '', regex=True)\n",
    "    .str.replace(r'\\s+', ' ', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# üóìÔ∏è Parse inspection dates\n",
    "df['Inspection Date'] = pd.to_datetime(df['Inspection Date'], errors='coerce')\n",
    "\n",
    "# üßπ Deduplicate: keep only most recent inspection per address + zip\n",
    "df = df.sort_values(by='Inspection Date', ascending=False)\n",
    "df_deduped = df.drop_duplicates(subset=['ADDRESS_CLEAN', 'Zip']).reset_index(drop=True)\n",
    "print(f\"üìâ Deduplicated to: {df_deduped.shape[0]} unique locations\")\n",
    "\n",
    "# üè∑Ô∏è Define grocery and junk keyword lists\n",
    "grocery_keywords = [\n",
    "    'ALDI', 'JEWEL', 'MARIANO', 'WHOLE FOODS', 'FOOD MARKET',\n",
    "    'SUPERMARKET', 'TRADER JOES', 'CERMARK', 'FRESH MARKET',\n",
    "    'LOS SAUCES', 'CERMAK', 'BUFFALO FOODS', 'SUPER LEON',\n",
    "    'AL EMAAN', 'TONYS', 'PETES'\n",
    "]\n",
    "\n",
    "junk_keywords = [\n",
    "    r'7[-‚Äì\\s]?ELEVEN', 'DOLLAR', 'CIRCLE K', 'SHELL', 'MOBIL',\n",
    "    'GAS', 'CONVENIENCE', 'MINI MART', 'WALGREENS', 'CVS',\n",
    "    'BP', 'CITGO', 'EXXON', 'AMOCO'\n",
    "]\n",
    "\n",
    "# üö© Flag junk and grocery stores\n",
    "df_deduped['IS_JUNK_STORE'] = df_deduped['DBA_NAME_CLEAN'].apply(\n",
    "    lambda name: any(re.search(pattern, name) for pattern in junk_keywords)\n",
    ")\n",
    "\n",
    "df_deduped['IS_REAL_GROCERY'] = df_deduped['DBA_NAME_CLEAN'].apply(\n",
    "    lambda name: any(keyword in name for keyword in grocery_keywords)\n",
    ")\n",
    "\n",
    "# üçé Add extra signal from violations\n",
    "produce_hints = ['fruit', 'vegetable', 'cut', 'salad', 'raw', 'cold', 'prep']\n",
    "df_deduped['HAS_PRODUCE_FLAG'] = df_deduped['Violations'].fillna('').str.lower().apply(\n",
    "    lambda v: any(word in v for word in produce_hints)\n",
    ")\n",
    "df_deduped['IS_REAL_GROCERY'] = df_deduped['IS_REAL_GROCERY'] | df_deduped['HAS_PRODUCE_FLAG']\n",
    "\n",
    "# üö´ Remove conflicting labels (prioritize real grocery)\n",
    "conflicts = df_deduped[df_deduped['IS_REAL_GROCERY'] & df_deduped['IS_JUNK_STORE']]\n",
    "df_deduped.loc[conflicts.index, 'IS_JUNK_STORE'] = False\n",
    "\n",
    "# üíæ Save cleaned dataset\n",
    "os.makedirs(os.path.dirname(CLEAN_PATH), exist_ok=True)\n",
    "df_deduped.to_csv(CLEAN_PATH, index=False)\n",
    "print(f\"‚úÖ Cleaned dataset saved to: {CLEAN_PATH}\")\n",
    "\n",
    "# üó∫Ô∏è Build interactive map\n",
    "m = folium.Map(location=[41.8781, -87.6298], zoom_start=11)\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "for _, row in df_deduped.iterrows():\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        continue\n",
    "\n",
    "    if row['IS_REAL_GROCERY']:\n",
    "        color, icon = 'green', 'shopping-cart'\n",
    "    elif row['IS_JUNK_STORE']:\n",
    "        color, icon = 'red', 'remove'\n",
    "    else:\n",
    "        color, icon = 'gray', 'info-sign'\n",
    "\n",
    "    popup = f\"{row['DBA Name']}<br>{row['Address']}<br>ZIP: {int(row['Zip']) if pd.notnull(row['Zip']) else ''}\"\n",
    "    folium.Marker(\n",
    "        location=[lat, lon],\n",
    "        popup=popup,\n",
    "        icon=folium.Icon(color=color, icon=icon)\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# üíæ Save map to file\n",
    "os.makedirs(os.path.dirname(MAP_PATH), exist_ok=True)\n",
    "m.save(MAP_PATH)\n",
    "print(f\"üó∫Ô∏è Map saved to: {MAP_PATH}\")\n",
    "\n",
    "# ‚úÖ Save labeled + deduped grocery dataset for analysis/visualization\n",
    "df_deduped.to_csv('../data/cleaned/grocery_stores_cleaned_v1.csv', index=False)\n",
    "print(\"‚úÖ grocery_stores_cleaned_v1.csv saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
